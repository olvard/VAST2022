{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5b/lx_h1w013634ddq6xwrjnf500000gn/T/ipykernel_85123/4054335030.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  filtered_participant1 = filtered_participant1.append(filtered_participant1_2)\n",
      "/var/folders/5b/lx_h1w013634ddq6xwrjnf500000gn/T/ipykernel_85123/4054335030.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  filtered_participant2 = filtered_participant2.append(filtered_participant2_2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "participants1 = pd.read_csv('Datasets/Activity Logs/ParticipantStatusLogs1.csv')\n",
    "participants2 = pd.read_csv('Datasets/Activity Logs/ParticipantStatusLogs2.csv')\n",
    "participants1.drop(['hungerStatus', 'sleepStatus', 'apartmentId', 'availableBalance', 'jobId', 'financialStatus', 'dailyFoodBudget', 'weeklyExtraBudget'], axis=1, inplace=True)\n",
    "participants2.drop(['hungerStatus', 'sleepStatus', 'apartmentId', 'availableBalance', 'jobId', 'financialStatus', 'dailyFoodBudget', 'weeklyExtraBudget'], axis=1, inplace=True)\n",
    "\n",
    "filtered_participant1 = participants1[participants1['participantId'] == 0]\n",
    "filtered_participant2 = participants1[participants1['participantId'] == 1]\n",
    "\n",
    "filtered_participant1_2 = participants2[participants2['participantId'] == 0]\n",
    "filtered_participant2_2 = participants2[participants2['participantId'] == 1]\n",
    "\n",
    "filtered_participant1 = filtered_participant1.append(filtered_participant1_2)\n",
    "filtered_participant2 = filtered_participant2.append(filtered_participant2_2)\n",
    "\n",
    "\n",
    "# filtered_participant1.to_csv('Datasets/Cleaned/ParticipantStatusLogs0.csv', index=False)\n",
    "# filtered_participant2.to_csv('Datasets/Cleaned/ParticipantStatusLogs1.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_x   -4762.190669\n",
      "min_y     -30.083591\n",
      "max_x   -4640.735188\n",
      "max_y      74.405547\n",
      "dtype: float64\n",
      "min_x    2610.000000\n",
      "min_y    7806.354912\n",
      "max_x    2650.000000\n",
      "max_y    7850.037195\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from shapely.wkt import loads\n",
    "\n",
    "df = pd.read_csv('Datasets/Attributes/Buildings.csv')\n",
    "df.drop(['buildingId', 'buildingType', 'maxOccupancy', 'units'], axis=1, inplace=True)\n",
    "\n",
    "def parse_polygon(polygon_str):\n",
    "    return loads(polygon_str)\n",
    "\n",
    "# Apply the function to create a new column with Shapely geometries\n",
    "df['geometry'] = df['location'].apply(parse_polygon)\n",
    "\n",
    "# Extract extents using the bounds attribute\n",
    "df['min_x'] = df['geometry'].apply(lambda geom: geom.bounds[0])\n",
    "df['min_y'] = df['geometry'].apply(lambda geom: geom.bounds[1])\n",
    "df['max_x'] = df['geometry'].apply(lambda geom: geom.bounds[2])\n",
    "df['max_y'] = df['geometry'].apply(lambda geom: geom.bounds[3])\n",
    "\n",
    "# Create a new DataFrame with the extents\n",
    "extents_df = df[['min_x', 'min_y', 'max_x', 'max_y']]\n",
    "\n",
    "min_values = extents_df.min(axis=0)\n",
    "max_values = extents_df.max(axis=0)\n",
    "\n",
    "print(min_values)\n",
    "print(max_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       participantId           travelStartTime                        purpose\n",
      "4866             715 2022-03-01 16:35:00+00:00  Recreation (Social Gathering)\n",
      "6837             715 2022-03-01 19:40:00+00:00  Recreation (Social Gathering)\n",
      "12522            715 2022-03-02 15:35:00+00:00  Recreation (Social Gathering)\n",
      "13800            715 2022-03-02 18:10:00+00:00  Recreation (Social Gathering)\n",
      "15155            715 2022-03-02 19:45:00+00:00  Recreation (Social Gathering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5b/lx_h1w013634ddq6xwrjnf500000gn/T/ipykernel_3918/2155971661.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_participants['travelStartTime'] = pd.to_datetime(filtered_participants['travelStartTime'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the CSV file\n",
    "participants = pd.read_csv('Datasets/Journals/TravelJournal.csv')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "participants.drop([ 'travelStartLocationId','travelEndTime','travelEndLocationId','checkInTime','checkOutTime','startingBalance','endingBalance'], axis=1, inplace=True)\n",
    "\n",
    "# Filter rows where 'currentMode' is 'Transport'\n",
    "filtered_participants = participants[participants['purpose'] == 'Recreation (Social Gathering)']\n",
    "\n",
    "filtered_participants['travelStartTime'] = pd.to_datetime(filtered_participants['travelStartTime'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Convert timestamp to datetime format for comparison\n",
    "\n",
    "# filtered_participants['travelEndTime'] = pd.to_datetime(filtered_participants['travelEndTime'])\n",
    "\n",
    "\n",
    "# Sample 5 participant IDs\n",
    "sample_participantIds = filtered_participants['participantId'].sample(n=1, random_state=42)\n",
    "\n",
    "# Filter the dataframe to include only the sampled participant IDs\n",
    "combined_df = filtered_participants[filtered_participants['participantId'].isin(sample_participantIds)]\n",
    "\n",
    "print(combined_df.head())\n",
    "# Save the cleaned data\n",
    "# filtered_participants.to_csv('Datasets/FilteredTravelJournal02.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
